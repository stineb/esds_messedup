[
["primers.html", "Environmental Systems Data Science Chapter 1 Primers 1.1 Exercises 1.2 How to use Bookdown and Markdown", " Environmental Systems Data Science Loïc Pellissier, Joshua Payne, Benjamin Stocker 2020-06-24 Chapter 1 Primers (Youtube videos can be embedded, according to this, but it didn’t work for me.) 1.1 Exercises 1.1.1 Overview Input: Reads for the first time the dataset 1 of two (Swiss) FLUXNET sites at high temporal resolution with 3-4 measures. Output: Learned about the data structure and the capacity to explore the content of the dataframe and visualize it so that it can be analysed in the next session. Data: Dataset 1 First hands-on with one of two (Swiss) FLUXNET sites at high temporal resolution with 3-4 measureswith high-resolution fluxnet dataset Contents Content and operations: Managing the workspace and data Basic operations in R RStudio, debugging Reading a table into a data frame Objects, data frames, lists Applying a function, loop, etc. Simple plotting Making workflow reproducible RMarkdown Coding Best practices Modularity Version control with git (for dummies: GitHub, fork, clone, commit, push, pull, branch) 1.1.2 Reading data into R Load libraries. library(readr) library(tidyverse) ## ── Attaching packages ─────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.1 ✓ dplyr 1.0.0 ## ✓ tibble 3.0.1 ✓ stringr 1.4.0 ## ✓ tidyr 1.1.0 ✓ forcats 0.5.0 ## ✓ purrr 0.3.4 ## ── Conflicts ────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Read data from Laegern site. df_fluxes &lt;- read_csv(&quot;./data/FLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2014_1-3.csv&quot;, ) ## Parsed with column specification: ## cols( ## .default = col_double() ## ) ## See spec(...) for full column specifications. Plot something. ggplot(data = slice(df_fluxes, 1:1000), aes(x = TIMESTAMP_START, NEE_VUT_REF)) + geom_line() 1.2 How to use Bookdown and Markdown This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: nothing install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) If you want to generate PDF output, you will need to install LaTeX. For R Markdown users who have not installed LaTeX before, we recommend that you install TinyTeX (https://yihui.name/tinytex/): install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # install TinyTeX Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading `#`. "],
["big-data-for-environmental-sciences.html", "Chapter 2 Big Data for environmental sciences 2.1 Exercises", " Chapter 2 Big Data for environmental sciences 2.1 Exercises We have time series data obtained from multiple sites. A common task is to complement our data with information about the sites (meta data), or with data from other sources and analyse it using this additional data. In this exercise, you will learn to… 2.1.1 Overview Input: From the last session they learned how to look at two flux tower site of dataset 1. Output: They have gotten familiar with the dataset 2, which contains multiple site Content Meta data Combining data: For our set of FLUXNET sites, collect data from other sources (global fields, remote sensing) Finding, accessing, downloading, and reading environmental data from the web, web scraping MODIS, Landsat, Google Earth Engine, Worldclim, Chelsa, CRU, (some re-analysis), CMIP5 from Urs, HWSD, ETOPO1, Biome classification, IGBP veg types, Koeppen-Geiger climate, …… Merging, nesting Formats: geo data: raster, NetCDF, CSV, shapefile bash, cron, wget, grep, system, RegExp 2.1.2 Read multiple files Find all daily time series data in the &quot;./data&quot; directory. Files are identified here by their name, which contains the pattern &quot;DD&quot; (for ‘daily’). filelist &lt;- list.files(&quot;./data&quot;, pattern = &quot;DD&quot;) This returns 19 files for 19 sites. We can read them in at once using a simple loop. Here, we are creating a list of data frames of length 19. library(readr) list_df &lt;- list() for (ifil in filelist){ list_df[[ifil]] &lt;- read_csv(paste0(&quot;./data/&quot;, ifil)) } In tidyverse, this could be done on one line by: library(purrr) list_df &lt;- purrr::map(as.list(filelist), ~read_csv(paste0(&quot;./data/&quot;, .))) ## This returns a unnamed list. Let&#39;s add names as done above. names(list_df) &lt;- filelist It may be unpractical to have the different dataframes as elements of a list. In fact, the data frames read in here each have similar shapes. I.e., they share the same columns (but differ by their number of rows, and of course, by their data values). This suggests that we can “stack” each dataframes along rows. library(dplyr) df_allsites &lt;- bind_rows(list_df, .id = &quot;siteid&quot;) This creates one single data frame containing all sites’ data (&gt;90’000 rows), and adds a column named &quot;siteid&quot; that is automatically created by using the names of the list elements of list_df. "],
["data-scraping-and-wrangling.html", "Chapter 3 Data scraping and wrangling 3.1 Exercises", " Chapter 3 Data scraping and wrangling 3.1 Exercises Input: The students Output: The student will produce a plant functional trait maps for Europe that can be considered later as a predictor. They have c about Biome classification, IGBP veg types Data: Dataset 2 in particular the geographic locations for which vegetation types will be produced in combination with plant occurrences (GBIF) and plant trait data (leaf trait - TRY). "],
["model-data-fusion.html", "Chapter 4 Model-data fusion 4.1 Exercises", " Chapter 4 Model-data fusion 4.1 Exercises Input: Dataset 1 (half-hourly) read, aggregated to daily values, cleaned and gapfilled Output: Linear regression (GPP ~ PAR); optimized modified model (GPP ~ PAR, T, VPD, soil moisture); Bayesian calibration? Data: LUE model to FLUXNET GPP "],
["supervised-learning.html", "Chapter 5 Supervised learning", " Chapter 5 Supervised learning We have finished a nice book. "],
["unsupervised-learning.html", "Chapter 6 Unsupervised learning", " Chapter 6 Unsupervised learning We have finished a nice book. "],
["references.html", "References", " References "]
]
